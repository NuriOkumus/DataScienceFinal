# Kütüphaneleri Yükle
library(mice)
library(MASS) # Pima veriseti için
# 1. Veriyi Hazırla (Sınav Senaryosu)
# Pima.tr verisetini kullanalım (MASS kütüphanesinden)
data(Pima.tr)
force(Pima.tr)
summary(Pima.tr)
# Sınavda bazen kendi eksik verimizi yaratmamız istenebilir veya var olanı inceleriz.
# Örnek: Rastgele NA değeri atayalım (Eğitim amaçlı)
set.seed(123)
Pima_miss <- Pima.tr
Pima_miss[sample(1:nrow(Pima_miss), 20), "bmi"] <- NA # BMI değişkeninde 20 rastgele kayıp
# 2. Eksik Veri Analizi (Pattern)
# md.pattern() fonksiyonu eksik verinin yapısını gösterir.
# Hangi satırlarda eksik var? Sadece BMI mı eksik?
md.pattern(Pima_miss)
# 3. MICE ile Doldurma (Imputation)
# m=5 : 5 farklı doldurulmuş veri seti oluştur.
# method='pmm' : Predictive Mean Matching (Varsayılan ve en güvenlisi)
# maxit=5 : Her doldurma için 5 iterasyon (Hızlı olsun diye az tuttuk, default 5-10)
imputed_data <- mice(Pima_miss, m = 5, method = 'pmm', maxit = 5, seed = 500)
# Özeti görelim
summary(imputed_data)
# 4. Doldurulmuş Veriyi Çekme (Complete)
# Eylemlerden birini seçip tam veri setini almak için complete() kullanılır.
# action=1 : 1 numaralı doldurulmuş veriyi getir.
completed_data_1 <- complete(imputed_data, action = 1)
# Kontrol edelim: Artık NA var mı?
sum(is.na(completed_data_1)) # 0 olmalı
# 5. Modelleme ve Pooling (İleri Seviye - Sınavda Çıkabilir)
# 5 ayrı veri setinin hepsiyle model kurup sonuçları birleştirmek en doğrusudur.
# with() fonksiyonu her bir 'm' datası için modeli çalıştırır.
fit_mice <- with(data = imputed_data, exp = lm(bmi ~ age + glu + npreg))
# pool() fonksiyonu bu 5 modelin sonuçlarını birleştirir (Rubin's Rules).
pooled_results <- pool(fit_mice)
# Sonuçları görelim
summary(pooled_results)
# Kütüphaneleri Yükle
library(MASS) # Pima verisi için
library(tidyverse) # ggplot2 ve veri manipülasyonu için
# 1. Veriyi Hazırla
data(Pima.tr)
# PCA sadece sayısal değişkenlere uygulanır.
# Son sütun "type" kategorik olduğu için çıkarıyoruz.
Pima_numeric <- Pima.tr[, -8]
# Kontrol
head(Pima_numeric)
# 2. PCA Uygula (prcomp)
# scale = TRUE : Çok ÖNEMLİ! Değişkenleri aynı ölçeğe getirir.
pca_result <- prcomp(Pima_numeric, scale = TRUE)
View(pca_result)
# Özet Sonuçlar
summary(pca_result)
# 3. Yükler (Loadings / Rotation)
# Hangi değişken hangi PC'yi oluşturuyor?
print(pca_result$rotation)
# 4. Görselleştirme 1: Scree Plot (Elbow Method)
# Varyansları çizelim
screeplot(pca_result, type = "lines",
main = "Scree Plot of Pima Data")
# 5. Görselleştirme 2: Biplot
# Hem gözlemleri (noktalar) hem değişkenleri (oklar) aynı anda gösterir
biplot(pca_result, scale = 0, cex = 0.6)
# 6. Sınav Sorusu: PC Skorlarını Tahmin Etme (predict)
# Yeni bir veri geldiğinde (örn: Pima.te), mevcut PCA modeline göre yerini bulma
test_data_numeric <- Pima.te[, -8]
test_scores <- predict(pca_result, newdata = test_data_numeric)
head(test_scores)
View(pca_result)
library(MASS)
library(caret)
data(Pima.tr)
# Par(mfrow) komutu: Ekranı bölmek için (2 satır, 4 sütun)
par(mfrow = c(2, 4))
# Döngü ile hepsini çizelim
for (i in 1:7) {
hist(Pima.tr[, i],
main = names(Pima.tr)[i], # Başlık
xlab = "Değer", # X ekseni
col = "lightblue"
)
}
# Ekranı sıfırla
par(mfrow = c(1, 1))
# x: Değişkenler (Sütun 1'den 7'ye)
# y: Sonuç (Sütun 8 - type)
# plot: "box" (Kutu grafiği en net olanıdır)
# scales: İlişkileri rahat görelim diye serbest bıraktık
# auto.key: Lejant ekle
featurePlot(
x = Pima.tr[, 1:7],
y = Pima.tr$type,
plot = "box",
scales = list(y = list(relation = "free")),
auto.key = list(columns = 2)
)
library(MASS)
data(Pima.tr)
# 1. Basit bir Model Kuralım
# Hedef: BMI (Kilo indeksi)
# Değişkenler: Diğer her şey (nokta '.' hepsi demek)
# Not: Type (Yes/No) kategorik olduğu için onu şimdilik çıkarıyorum.
model_full <- lm(bmi ~ . - type, data = Pima.tr)
# Model Özeti (Karnesi)
summary(model_full)
# 2. Varsayımları Kontrol Etme (Diagnostics Plots) - ÇOK ÖNEMLİ!
# Ekranı 2x2 bölelim ki 4 grafiği bir arada görelim
par(mfrow = c(2, 2))
plot(model_full)
# Ekranı düzelt
par(mfrow = c(1, 1))
# step() fonksiyonu, AIC değerine bakarak en iyi modeli bulana kadar değişken atar.
model_reduced <- step(model_full, direction = "backward")
# En son kalan "Reduced Model"in özeti
summary(model_reduced)
# YORUM:
# YORUM:
# Full Model ile Reduced Model'in "Adjusted R-squared" değerlerini kıyasla.
library(caret)
library(MASS)
data(Pima.tr)
# 1. 10-Katlı Çapraz Doğrulama (10-Fold CV) Hazırlığı
# Amacımız: Modeli tek bir deneyle değil, 10 farklı parçada test edip ortalamasını almak.
# repeat=5: Bu işlemi 5 kere tekrarla (Sağlam olsun).
ctrl <- trainControl(
method = "repeatedcv",
number = 10,
repeats = 5
)
# 2. Logistic Regression Modeli Kurma ('glm')
# method = "glm" -> Generalized Linear Model (Logistic Reg için)
# preProcess = c("center", "scale") -> Veriyi standardize et (Sınav şartı!)
set.seed(123)
model_log <- train(type ~ .,
data = Pima.tr,
method = "glm",
preProcess = c("center", "scale"),
trControl = ctrl
)
# 3. Random Forest Modeli Kurma ('rf')
# method = "rf" -> Random Forest
set.seed(123)
model_rf <- train(type ~ .,
data = Pima.tr,
method = "rf",
preProcess = c("center", "scale"),
trControl = ctrl
)
# 4. Karşılaştırma (Result!)
# Hangi model daha başarılı?
results <- resamples(list(Logistic = model_log, RandomForest = model_rf))
summary(results)
# 5. Confusion Matrix (Final Testi)
# Modeli Pima.te (Test Verisi) üzerinde deneyelim.
# prediction (Tahmin) yapalım:
predictions_log <- predict(model_log, newdata = Pima.te)
# Matris Çizelim:
# positive = "Yes" (Bizim için önemli olan Hasta demek)
conf_matrix <- confusionMatrix(
data = predictions_log,
reference = Pima.te$type,
positive = "Yes"
)
print(conf_matrix)
library(MASS)
library(caret)
library(mice)
library(ggplot2)
library(randomForest)
# Verileri yükle
data(Pima.tr)
data(Pima.te)
# İşlem kolaylığı için training set üzerinden gidelim (soruların çoğu training üzerine)
df <- Pima.tr
library(MASS)
library(caret)
library(mice)
library(ggplot2)
library(randomForest)
# Verileri yükle
data(Pima.tr)
data(Pima.te)
# İşlem kolaylığı için training set üzerinden gidelim (soruların çoğu training üzerine)
df <- Pima.tr
md.pattern(Pima.tr)
?par
par(mfrow = c(3,3))
for(i in 1:7) {
hist(df[,i], main=names(df)[i],)
}
featurePlot(x = df[, 1:7], y = df$type, plot = "box")
featurePlot(x = df[, 1:7], y = df$type, plot = "box" , scales = list(y = list(relation="free")),)
?featurePlot()
?featurePlot()
featurePlot(x = df[, 1:7], y = df$type, plot = "box" , scales = TRUE)
featurePlot(x = df[, 1:7],
y = df$type,
plot = "box",
scales = list(y = list(relation = "free")))
# Gerekli kütüphanelerin yüklenmesi
library(MASS)
# Gerekli kütüphanelerin yüklenmesi
library(MASS)
library(caret)
library(mice)
library(tidyverse)
# Verinin yüklenmesi
data("Pima.tr")
data("Pima.te")
# NA kontrolü (Tüm değişkenler için)
anyNA(Pima.tr)
anyNA(Pima.te)
# 0 kontrolü (npreg ve type hariç)
# npreg ve type dışındaki sütunlardaki 0'ları NA yapabiliriz kontrol etmek için
tr_temp <- Pima.tr
tr_temp[, 2:7][tr_temp[, 2:7] == 0] <- NA
sum(is.na(tr_temp)) # Kaç tane eksik veri olduğunu verir
# Histogramlar ile dağılımı kontrol edebiliriz
par(mfrow = c(3, 3))
for (i in 1:7) {
hist(Pima.tr[, i], main = colnames(Pima.tr)[i], col = "skyblue")
}
featurePlot(
x = Pima.tr[, 1:7],
y = Pima.tr$type,
plot = "box",
scales = list(y = list(relation = "free"), x = list(rot = 90))
)
?trainControl
featurePlot(
x = Pima.tr[, 1:7],
y = Pima.tr$type,
plot = "box",
scales = list(y = list(relation = "free"), x = list(rot = 90))
)
# Logistic Regression
?train
# Logistic Regression
?train
library(caret)
# Logistic Regression
?train
install.packages("caret")
library(caret)
# Verinin yüklenmesi
data("Pima.tr")
# Gerekli kütüphanelerin yüklenmesi
library(MASS)
library(caret)
library(mice)
library(tidyverse)
install.packages("caret")
install.packages("caret")
library(caret)
# Logistic Regression
?train
# Logistic Regression
?train
set.seed(123)
model_logit <- train(type ~ .,
data = Pima.tr, method = "glm", family = "binomial",
preProcess = c("center", "scale"), trControl = ctrl
)
?trainControl
ctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 5)
# Logistic Regression
?train
set.seed(123)
model_logit <- train(type ~ .,
data = Pima.tr, method = "glm", family = "binomial",
preProcess = c("center", "scale"), trControl = ctrl
)
# Random Forest
set.seed(123)
model_rf <- train(type ~ .,
data = Pima.tr, method = "rf",
preProcess = c("center", "scale"), trControl = ctrl
)
# Tahminler
pred_logit <- predict(model_logit, Pima.te)
pred_rf <- predict(model_rf, Pima.te)
# Confusion Matrices
cm_logit <- confusionMatrix(pred_logit, Pima.te$type, positive = "Yes")
cm_rf <- confusionMatrix(pred_rf, Pima.te$type, positive = "Yes")
print(cm_logit)
print(cm_rf)
# Confusion Matrices
?confusionMatrix
new_patients <- data.frame(
npreg = c(4, 1),
glu = c(148, 85),
bp = c(72, 66),
skin = c(35, 29),
bmi = c(24.6, 26.6),
ped = c(0.627, 0.351),
age = c(40, 17)
)
predict(model_logit, new_patients)
pca_result <- prcomp(Pima.tr[, 1:7], scale = TRUE)
summary(pca_result)
plot(pca_result, type = "l", main = "Scree Plot")
# 13. Regression Assumptions:
model_bmi <- lm(bmi ~ npreg + glu + bp + skin + ped + age, data = Pima.tr)
par(mfrow = c(1, 1))
pca_result <- prcomp(Pima.tr[, 1:7], scale = TRUE)
summary(pca_result)
plot(pca_result, type = "l", main = "Scree Plot")
# 13. Regression Assumptions:
model_bmi <- lm(bmi ~ npreg + glu + bp + skin + ped + age, data = Pima.tr)
par(mfrow = c(2, 2))
plot(model_bmi)
# 16. R-squared:
summary(model_bmi)
# 17. Stepwise Regression:
full_model <- lm(bmi ~ ., data = Pima.tr) # 'type' sütununu çıkararak denemek gerekebilir
# bmi için sayısal model kuruyoruz:
full_model <- lm(bmi ~ npreg + glu + bp + skin + ped + age, data = Pima.tr)
step_model <- step(full_model, direction = "backward")
