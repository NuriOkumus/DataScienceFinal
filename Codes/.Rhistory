# Kütüphaneleri Yükle
library(mice)
library(MASS) # Pima veriseti için
# 1. Veriyi Hazırla (Sınav Senaryosu)
# Pima.tr verisetini kullanalım (MASS kütüphanesinden)
data(Pima.tr)
force(Pima.tr)
summary(Pima.tr)
# Sınavda bazen kendi eksik verimizi yaratmamız istenebilir veya var olanı inceleriz.
# Örnek: Rastgele NA değeri atayalım (Eğitim amaçlı)
set.seed(123)
Pima_miss <- Pima.tr
Pima_miss[sample(1:nrow(Pima_miss), 20), "bmi"] <- NA # BMI değişkeninde 20 rastgele kayıp
# 2. Eksik Veri Analizi (Pattern)
# md.pattern() fonksiyonu eksik verinin yapısını gösterir.
# Hangi satırlarda eksik var? Sadece BMI mı eksik?
md.pattern(Pima_miss)
# 3. MICE ile Doldurma (Imputation)
# m=5 : 5 farklı doldurulmuş veri seti oluştur.
# method='pmm' : Predictive Mean Matching (Varsayılan ve en güvenlisi)
# maxit=5 : Her doldurma için 5 iterasyon (Hızlı olsun diye az tuttuk, default 5-10)
imputed_data <- mice(Pima_miss, m = 5, method = 'pmm', maxit = 5, seed = 500)
# Özeti görelim
summary(imputed_data)
# 4. Doldurulmuş Veriyi Çekme (Complete)
# Eylemlerden birini seçip tam veri setini almak için complete() kullanılır.
# action=1 : 1 numaralı doldurulmuş veriyi getir.
completed_data_1 <- complete(imputed_data, action = 1)
# Kontrol edelim: Artık NA var mı?
sum(is.na(completed_data_1)) # 0 olmalı
# 5. Modelleme ve Pooling (İleri Seviye - Sınavda Çıkabilir)
# 5 ayrı veri setinin hepsiyle model kurup sonuçları birleştirmek en doğrusudur.
# with() fonksiyonu her bir 'm' datası için modeli çalıştırır.
fit_mice <- with(data = imputed_data, exp = lm(bmi ~ age + glu + npreg))
# pool() fonksiyonu bu 5 modelin sonuçlarını birleştirir (Rubin's Rules).
pooled_results <- pool(fit_mice)
# Sonuçları görelim
summary(pooled_results)
# Kütüphaneleri Yükle
library(MASS) # Pima verisi için
library(tidyverse) # ggplot2 ve veri manipülasyonu için
# 1. Veriyi Hazırla
data(Pima.tr)
# PCA sadece sayısal değişkenlere uygulanır.
# Son sütun "type" kategorik olduğu için çıkarıyoruz.
Pima_numeric <- Pima.tr[, -8]
# Kontrol
head(Pima_numeric)
# 2. PCA Uygula (prcomp)
# scale = TRUE : Çok ÖNEMLİ! Değişkenleri aynı ölçeğe getirir.
pca_result <- prcomp(Pima_numeric, scale = TRUE)
View(pca_result)
# Özet Sonuçlar
summary(pca_result)
# 3. Yükler (Loadings / Rotation)
# Hangi değişken hangi PC'yi oluşturuyor?
print(pca_result$rotation)
# 4. Görselleştirme 1: Scree Plot (Elbow Method)
# Varyansları çizelim
screeplot(pca_result, type = "lines",
main = "Scree Plot of Pima Data")
# 5. Görselleştirme 2: Biplot
# Hem gözlemleri (noktalar) hem değişkenleri (oklar) aynı anda gösterir
biplot(pca_result, scale = 0, cex = 0.6)
# 6. Sınav Sorusu: PC Skorlarını Tahmin Etme (predict)
# Yeni bir veri geldiğinde (örn: Pima.te), mevcut PCA modeline göre yerini bulma
test_data_numeric <- Pima.te[, -8]
test_scores <- predict(pca_result, newdata = test_data_numeric)
head(test_scores)
View(pca_result)
library(MASS)
library(caret)
data(Pima.tr)
# Par(mfrow) komutu: Ekranı bölmek için (2 satır, 4 sütun)
par(mfrow = c(2, 4))
# Döngü ile hepsini çizelim
for (i in 1:7) {
hist(Pima.tr[, i],
main = names(Pima.tr)[i], # Başlık
xlab = "Değer", # X ekseni
col = "lightblue"
)
}
# Ekranı sıfırla
par(mfrow = c(1, 1))
# x: Değişkenler (Sütun 1'den 7'ye)
# y: Sonuç (Sütun 8 - type)
# plot: "box" (Kutu grafiği en net olanıdır)
# scales: İlişkileri rahat görelim diye serbest bıraktık
# auto.key: Lejant ekle
featurePlot(
x = Pima.tr[, 1:7],
y = Pima.tr$type,
plot = "box",
scales = list(y = list(relation = "free")),
auto.key = list(columns = 2)
)
library(MASS)
data(Pima.tr)
# 1. Basit bir Model Kuralım
# Hedef: BMI (Kilo indeksi)
# Değişkenler: Diğer her şey (nokta '.' hepsi demek)
# Not: Type (Yes/No) kategorik olduğu için onu şimdilik çıkarıyorum.
model_full <- lm(bmi ~ . - type, data = Pima.tr)
# Model Özeti (Karnesi)
summary(model_full)
# 2. Varsayımları Kontrol Etme (Diagnostics Plots) - ÇOK ÖNEMLİ!
# Ekranı 2x2 bölelim ki 4 grafiği bir arada görelim
par(mfrow = c(2, 2))
plot(model_full)
# Ekranı düzelt
par(mfrow = c(1, 1))
# step() fonksiyonu, AIC değerine bakarak en iyi modeli bulana kadar değişken atar.
model_reduced <- step(model_full, direction = "backward")
# En son kalan "Reduced Model"in özeti
summary(model_reduced)
# YORUM:
# YORUM:
# Full Model ile Reduced Model'in "Adjusted R-squared" değerlerini kıyasla.
library(caret)
library(MASS)
data(Pima.tr)
# 1. 10-Katlı Çapraz Doğrulama (10-Fold CV) Hazırlığı
# Amacımız: Modeli tek bir deneyle değil, 10 farklı parçada test edip ortalamasını almak.
# repeat=5: Bu işlemi 5 kere tekrarla (Sağlam olsun).
ctrl <- trainControl(
method = "repeatedcv",
number = 10,
repeats = 5
)
# 2. Logistic Regression Modeli Kurma ('glm')
# method = "glm" -> Generalized Linear Model (Logistic Reg için)
# preProcess = c("center", "scale") -> Veriyi standardize et (Sınav şartı!)
set.seed(123)
model_log <- train(type ~ .,
data = Pima.tr,
method = "glm",
preProcess = c("center", "scale"),
trControl = ctrl
)
# 3. Random Forest Modeli Kurma ('rf')
# method = "rf" -> Random Forest
set.seed(123)
model_rf <- train(type ~ .,
data = Pima.tr,
method = "rf",
preProcess = c("center", "scale"),
trControl = ctrl
)
# 4. Karşılaştırma (Result!)
# Hangi model daha başarılı?
results <- resamples(list(Logistic = model_log, RandomForest = model_rf))
summary(results)
# 5. Confusion Matrix (Final Testi)
# Modeli Pima.te (Test Verisi) üzerinde deneyelim.
# prediction (Tahmin) yapalım:
predictions_log <- predict(model_log, newdata = Pima.te)
# Matris Çizelim:
# positive = "Yes" (Bizim için önemli olan Hasta demek)
conf_matrix <- confusionMatrix(
data = predictions_log,
reference = Pima.te$type,
positive = "Yes"
)
print(conf_matrix)
