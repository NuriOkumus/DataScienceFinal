# 05. Sınıflandırma (Classification) Teorisi

Hedefimiz bir sayı tahmin etmek değil, bir **ETİKET** yapıştırmaktır: (Hasta/Sağlıklı, Evet/Hayır).
Bu işte iki temel yöntem kullanırız:

## 1. Logistic Regression (glm)
*   **Mantık:** Lineer regresyonun `S` çizerek 0 ile 1 arasına sıkıştırılmış halidir (Sigmoid fonksiyonu).
*   **Avantajı:** Yorumlaması kolaydır. Hangi değişkenin olasılığı nasıl artırdığını (Odds Ratio) net söyler.
*   **Dezavantajı:** Veri çok karmaşıksa (Linear değilse) başarısız olabilir.

## 2. Random Forest (rf)
*   **Mantık:** "Akıl akıldan üstündür." Tek bir ağaç yerine yüzlerce Karar Ağacı (Decision Tree) kurar. Hepsi oylama yapar. Çoğunluk ne derse o olur.
*   **Avantajı:** Genelde en yüksek başarıyı (Accuracy) bu verir.
*   **Dezavantajı:** "Black Box"tır. Neden o kararı verdiğini anlamak zordur.

---

## 3. Cross Validation (Çapraz Doğrulama) ⭐

Modeli eğitirken aynı veriyi hem eğitim hem test için kullanırsak **overfitting** (ezberleme) riski oluşur. Bunu önlemek için **Cross Validation** kullanırız.

### 10-Fold CV Nasıl Çalışır?
1. Veriyi **10 eşit parçaya** böl
2. Her seferinde **1 parçayı test**, **9 parçayı eğitim** için kullan
3. Bu işlemi 10 kez tekrarla (her parça 1 kez test olur)
4. 10 sonucun **ortalamasını** al

### 5 Replicate Ne Demek?
Tüm bu 10-fold işlemini **5 kez farklı rastgele bölünmelerle** tekrarla. Toplamda 50 model kurulur!

```r
# Cross Validation Objesi Oluşturma
library(caret)

ctrl <- trainControl(
    method = "repeatedcv",  # Tekrarlı CV
    number = 10,            # 10-Fold
    repeats = 5             # 5 Replicate
)

# Model Eğitimi (preProcess ile ölçekleme!)
model <- train(
    type ~ ., 
    data = Pima.tr, 
    method = "glm",         # veya "rf" Random Forest için
    preProcess = c("center", "scale"),
    trControl = ctrl
)
```

---

## 4. Confusion Matrix (Karışıklık Matrisi) - SINAVIN KALBİ ❤️

Model tahminlerini yaptıktan sonra bir tablo oluştururuz:

| | Tahmin: Hasta (Pos) | Tahmin: Sağlam (Neg) |
|---|---|---|
| **Gerçek: Hasta** | **TP** (True Positive) | **FN** (False Negative) |
| **Gerçek: Sağlam** | **FP** (False Positive) | **TN** (True Negative) |

### Metrik Formülleri (EZBERLE!)

| Metrik | Formül | Anlamı |
|--------|--------|--------|
| **Accuracy** | `(TP + TN) / (TP+TN+FP+FN)` | Toplamda ne kadarını bildik? |
| **Sensitivity** (Recall) | `TP / (TP + FN)` | Hastaların kaçını yakaladık? |
| **Specificity** | `TN / (TN + FP)` | Sağlamların kaçına sağlam dedik? |
| **Precision** | `TP / (TP + FP)` | "Hasta" dediklerimizin kaçı gerçekten hasta? |

> **Sınav İpucu:** Sensitivity doktorlar için kritik! Hastayı kaçırmak (FN) çok tehlikeli.

---

## 5. R Kodu: Tam Akış

```r
library(MASS)
library(caret)
data(Pima.tr)
data(Pima.te)

# 1. Cross Validation Ayarı
ctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 5)

# 2. Logistic Regression Modeli
set.seed(123)
model_glm <- train(type ~ ., data = Pima.tr, method = "glm",
                   preProcess = c("center", "scale"), trControl = ctrl)

# 3. Random Forest Modeli
set.seed(123)
model_rf <- train(type ~ ., data = Pima.tr, method = "rf",
                  preProcess = c("center", "scale"), trControl = ctrl)

# 4. Test Seti Üzerinde Confusion Matrix
pred_glm <- predict(model_glm, Pima.te)
confusionMatrix(pred_glm, Pima.te$type, positive = "Yes")
```

---

## 6. Yeni Hasta Tahmini

```r
yeni_hastalar <- data.frame(
    npreg = c(4, 1), 
    glu = c(148, 85), 
    bp = c(72, 66), 
    skin = c(35, 29), 
    bmi = c(24.6, 26.6), 
    ped = c(0.627, 0.351), 
    age = c(40, 17) 
)

predict(model_rf, newdata = yeni_hastalar)
# Beklenen: Patient 1 = Yes, Patient 2 = No
```

