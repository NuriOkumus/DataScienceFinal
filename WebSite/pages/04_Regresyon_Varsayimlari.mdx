# 04. Regresyon VarsayÄ±mlarÄ± (Diagnostics) - En Kritik Konu! ğŸš¨

Bir Lineer Regresyon modeli kurduk (`lm`). Peki bu model gÃ¼venilir mi? Bunu anlamak iÃ§in modele **"saÄŸlÄ±k kontrolÃ¼" (Diagnostics)** yapmalÄ±yÄ±z.

SÄ±navda hoca sana **4'lÃ¼ bir grafik (Plot)** verir ve yorumlamanÄ± ister. En Ã¶nemli ikisi ÅŸunlardÄ±r:

```r
# 1. Modeli Kurma
library(MASS)
data(Pima.tr)

# Basit bir model: BMI tahmin et
# (Type hariÃ§ diÄŸer hepsi)
model_full <- lm(bmi ~ . - type, data = Pima.tr)

summary(model_full)
```

---

## 1. Residuals vs Fitted (Homoscedasticity KontrolÃ¼)

Bu grafik bize ÅŸunu sÃ¶yler: **"Modelin hatalarÄ± (residuals) tutarlÄ± mÄ±?"**

*   **Ä°deal Olan:** Noktalar (hatalar), 0 Ã§izgisinin etrafÄ±nda **rastgele bir bulut** gibi daÄŸÄ±lmalÄ±dÄ±r. HiÃ§bir ÅŸekil (U harfi, huni ÅŸekli vb.) OLMAMALIDIR.
    *   Buna "Homoscedasticity" (EÅŸ VaryanslÄ±lÄ±k) denir. Ä°yi bir ÅŸeydir. âœ…

*   **Sorunlu Olan:**
    *   **Huni (Funnel) Åekli:** Noktalar solda dar baÅŸlayÄ±p saÄŸa doÄŸru aÃ§Ä±lÄ±yorsa (yelpaze gibi).
    *   **U Åekli (Non-Linearity):** Noktalar bir muz gibi kÄ±vrÄ±lÄ±yorsa.
    *   Bu duruma "Heteroscedasticity" denir. KÃ¶tÃ¼dÃ¼r. âŒ

> **SÄ±nav Åablon CevabÄ±:** "We check the Residuals vs Fitted plot for Homoscedasticity. We expect a random scatter of points around the horizontal line with no distinct pattern (like a funnel or curve). If a pattern exists, the assumption is violated."

---

## 2. Normal Q-Q Plot (Normality KontrolÃ¼)

Bu grafik bize ÅŸunu sÃ¶yler: **"Hatalar Normal DaÄŸÄ±lÄ±yor mu?"**

*   **Ä°deal Olan:** Noktalar, **kesik kesik Ã§izilen kÃ¶ÅŸegen Ã§izgisinin (diagonal line)** tam Ã¼stÃ¼ne inci gibi dizilmelidir. âœ…
*   **Sorunlu Olan:**
    *   UÃ§larda (baÅŸtan veya sondan) Ã§izgiden kopmalar, sapmalar varsa.
    *   S harfi Ã§iziyorsa.
    *   Buna "Non-Normality" denir. âŒ

```r
# 2. Diagnostics Plots (SaÄŸlÄ±k KontrolÃ¼)
# EkranÄ± 2x2 bÃ¶lelim
par(mfrow = c(2, 2))

# 4 sihirli grafik
plot(model_full)

# Ä°ÅŸimiz bitince ekranÄ± dÃ¼zeltelim
par(mfrow = c(1, 1))
```

---

## 3. Multicollinearity (Ã‡oklu BaÄŸlantÄ± Problemi)

**Nedir?** Modeldeki iki deÄŸiÅŸkenin birbirine Ã§ok benzemesidir.

**Ã–rnek:** Modele hem `bmi` hem de `skin` koymak. Ä°kisi de "ÅŸiÅŸmanlÄ±ÄŸÄ±" Ã¶lÃ§er. Modelin kafasÄ± karÄ±ÅŸÄ±r.

**Belirtileri:**
- Standart Hatalar (Std. Error) aÅŸÄ±rÄ± bÃ¼yÃ¼r
- KatsayÄ±lar anlamsÄ±z Ã§Ä±kar (p-value > 0.05)
- KatsayÄ± iÅŸaretleri beklenenin tersi olabilir

### VIF (Variance Inflation Factor) Testi

VIF deÄŸeri multicollinearity'yi Ã¶lÃ§er:
- **VIF = 1:** Korelasyon yok (ideal)
- **VIF > 5:** Dikkat! Potansiyel sorun
- **VIF > 10:** Ciddi sorun! DeÄŸiÅŸkeni Ã§Ä±kar

```r
# VIF Hesaplama
library(car)
vif(model_full)

# EÄŸer VIF > 5 olan varsa, o deÄŸiÅŸkeni modelden Ã§Ä±kar
```

**Ã‡Ã¶zÃ¼m:** VIF deÄŸeri yÃ¼ksek olan deÄŸiÅŸkenlerden birini modelden at!

---

## 4. R-Kare (Multiple vs Adjusted)

| Metrik | Ã–zellik | Ne Zaman Kullan? |
|--------|---------|------------------|
| **Multiple RÂ²** | Her deÄŸiÅŸken eklenince ARTAR (Ã§Ã¶p bile olsa) | KULLANMA! |
| **Adjusted RÂ²** | Gereksiz deÄŸiÅŸken eklenince DÃœÅER | HER ZAMAN BUNA BAK! |

> **Kural:** Ä°ki modeli kÄ±yaslarken **her zaman Adjusted R-squared**'e bakÄ±lÄ±r.

---

## 5. Stepwise Regression (Otomatik Model SeÃ§imi)

`step()` fonksiyonu gereksiz deÄŸiÅŸkenleri otomatik atar.

```r
# Backward Elimination (Geriye DoÄŸru Eleme)
model_reduced <- step(model_full, direction = "backward")

# Sonucu gÃ¶r
summary(model_reduced)
```

### Stepwise Ã‡alÄ±ÅŸma MantÄ±ÄŸÄ±
1. TÃ¼m deÄŸiÅŸkenlerle baÅŸla (Full Model)
2. Her adÄ±mda AIC deÄŸerini hesapla
3. AIC'yi en Ã§ok dÃ¼ÅŸÃ¼ren deÄŸiÅŸkeni **Ã§Ä±kar**
4. AIC dÃ¼ÅŸmeyene kadar tekrarla

### âš ï¸ Stepwise EleÅŸtirisi (SÄ±nav Sorusu!)

Stepwise "greedy" (aÃ§gÃ¶zlÃ¼) bir algoritmadÄ±r. Riskleri:
- Her adÄ±mda lokal olarak en iyi kararÄ± verir, global optimumu kaÃ§Ä±rabilir
- p-value'lar inflate olabilir (Ã§ok test yapÄ±lÄ±yor)
- SonuÃ§lar sample'a Ã§ok baÄŸÄ±mlÄ±, farklÄ± veriyle farklÄ± model Ã§Ä±kar
- **Klinik/teorik bilgiyi gÃ¶rmezden gelir**

> **SÄ±nav CevabÄ±:** "Stepwise ignores domain knowledge. A clinically important variable might be removed just because it's not statistically significant in this particular sample."

---

## 6. Full vs Reduced Model KarÅŸÄ±laÅŸtÄ±rma

| Ã–zellik | Full Model | Reduced Model |
|---------|------------|---------------|
| DeÄŸiÅŸken SayÄ±sÄ± | Fazla | Az |
| Multiple RÂ² | Daha yÃ¼ksek | Daha dÃ¼ÅŸÃ¼k |
| Adjusted RÂ² | Belki dÃ¼ÅŸÃ¼k | Muhtemelen daha yÃ¼ksek |
| Yorumlama | Zor | Kolay |
| Overfitting Riski | YÃ¼ksek | DÃ¼ÅŸÃ¼k |

> **Parsimony Principle:** AynÄ± baÅŸarÄ±yÄ± veren iki modelden **daha basit olanÄ±** tercih et!
